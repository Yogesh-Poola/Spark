{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b614b8e-2cda-4bce-9955-2ead2536d060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataframe is made up of rows and columns and Transformation means modifying or manipulating these two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b37c3a2-e560-41e4-b4c2-cc1a132220da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Note : Columns can also be treated as Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e9855b-4d3e-490b-b69a-5a0f1910a5e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=6291763126987047#setting/sparkui/0322-101529-zoyr6fcn/driver-6829904482291996273\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=6291763126987047#setting/sparkui/0322-101529-zoyr6fcn/driver-6829904482291996273\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6040c63-8f65-4e04-a62c-c4f212b91988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").load(\"dbfs:/FileStore/shared_uploads/creationsbyyogesh@gmail.com/2015_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48d7a6dd-9d72-45ce-9880-43b22a79a9c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- DEST_COUNTRY_NAME: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b9c19e-5b37-4af9-9314-0df57bc40544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Creating a Dataframe\n",
    "1. We can create by reading from DataSources\n",
    "2. We can create manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fe69797-127c-4460-9a7b-cf42e45a8aea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We have already created a DataFrame by reading json data above. We will use the same DF as temp view so that we can run SQL Queries on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d671f5e-8c42-4778-a596-1aeeb63fadf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6477cf3-cc9b-4c7f-af60-a43b685d3d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can create Manual Schema which will cover the columns part of DF and we can also create Rows with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f43ba14-9d73-46b1-a2f6-f20650022250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "from pyspark.sql import Row\n",
    "myManualSchema = StructType(\n",
    "  [\n",
    "    StructField(\"Name\", StringType(), False),\n",
    "    StructField(\"Age\", LongType(), False),\n",
    "    StructField(\"Occupation\", StringType(), True)\n",
    "  ]\n",
    ")\n",
    "myRow = Row(\"Yogesh\",30,\"Data Engineer\")\n",
    "myNewDf = spark.createDataFrame([myRow],myManualSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f01089a-a743-4a1b-836e-a50d3fd40c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-------------+\n|  Name|Age|   Occupation|\n+------+---+-------------+\n|Yogesh| 30|Data Engineer|\n+------+---+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "myNewDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b5331f1-9022-4f3c-b64e-06fea8dc2726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# select and selectExpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fc3923b-0a6e-4b32-80cb-179c01fe70b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Remember we created a tempView above \"dfTable\". See below we can use SQL statements to query it just like in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "958c9df5-26f7-4c8d-be0f-5e1032a053b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th></tr></thead><tbody><tr><td>United States</td></tr><tr><td>United States</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States"
        ],
        [
         "United States"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select DEST_COUNTRY_NAME from dfTable LIMIT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "720708d9-7562-4df8-974e-c91d6049b4c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Or We can use Python and use methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df56e91-d2ca-4100-af7c-24896289f88a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|DEST_COUNTRY_NAME|\n+-----------------+\n|    United States|\n|    United States|\n+-----------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a4fb755-927d-4ebe-8242-ea5fc7d6484d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Returning Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cda30333-8abf-4ef6-be27-4857c8f55f8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th></tr></thead><tbody><tr><td>United States</td><td>Romania</td></tr><tr><td>United States</td><td>Croatia</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "Romania"
        ],
        [
         "United States",
         "Croatia"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME from dfTable LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8434e2bc-c002-45d5-8f93-0e8e42c9bb41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n+-----------------+-------------------+\n|    United States|            Romania|\n|    United States|            Croatia|\n+-----------------+-------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d369eb9f-d69a-4549-b149-44b5c4175421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n|         DEST|DEST_COUNTRY_NAME|\n+-------------+-----------------+\n|United States|    United States|\n|United States|    United States|\n+-------------+-----------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"DEST_COUNTRY_NAME AS DEST\", \"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2e8e15-7baa-4876-9549-658a705e68cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------------+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|WITHIN_COUNTRY|\n+-----------------+-------------------+-----+--------------+\n|    United States|            Romania|   15|         false|\n|    United States|            Croatia|    1|         false|\n+-----------------+-------------------+-----+--------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"*\",\"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) AS WITHIN_COUNTRY\")\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7152c013-97a9-4b06-9c61-d8bb408f7600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------------+\n| avg(count)|count(DISTINCT ORIGIN_COUNTRY_NAME)|\n+-----------+-----------------------------------+\n|1770.765625|                                125|\n+-----------+-----------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"AVG(count)\",\"count(distinct(ORIGIN_COUNTRY_NAME))\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92d03dc2-baec-4ec3-a3a9-b6102306f91a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8210cb07-6193-4f2f-95ab-dc853826a7fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n+-----------------+-------------------+-----+---+\n|    United States|            Romania|   15|  1|\n|    United States|            Croatia|    1|  1|\n+-----------------+-------------------+-----+---+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, expr\n",
    "df.select(expr(\"*\"),lit(1).alias(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "726a4703-7a86-4a9f-97c4-d2a39a4bdc92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "lit does not work in selectExpr because selectExpr expects a raw SQL string that can be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b711cff-8ae8-47c9-9c8b-d6dd99a7a999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|one|\n+-----------------+-------------------+-----+---+\n|    United States|            Romania|   15|  1|\n|    United States|            Croatia|    1|  1|\n+-----------------+-------------------+-----+---+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.selectExpr(\"*\",\"1 AS one\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25fb618f-360e-4cb7-9cbb-8d95e1959cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "441b9bcd-b5ec-4094-8602-7cfa2af1a59b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n+-----------------+-------------------+-----+---------+\n|    United States|            Romania|   15|        1|\n|    United States|            Croatia|    1|        1|\n+-----------------+-------------------+-----+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"numberOne\",lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69eef983-5c3e-47e7-8403-36de9fee3adc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Note : Columns are nothing but expressions in Spark. Notice that the withColumn function takes two arguments: the column name and the expression that will create the value for that given row in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9909f9-1e8b-40fa-aa8c-f6703544a693",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n+-----------------+-------------------+-----+-------------+\n|    United States|            Romania|   15|        false|\n|    United States|            Croatia|    1|        false|\n+-----------------+-------------------+-----+-------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"withinCountry\",expr(\"DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb70e3ed-0fbf-44fa-a990-26c7c5f71afe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06069fb0-b727-4ee6-849e-ee45dc1a804d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----+\n|         Dest|ORIGIN_COUNTRY_NAME|count|\n+-------------+-------------------+-----+\n|United States|            Romania|   15|\n|United States|            Croatia|    1|\n+-------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\",\"Dest\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48287f8-ec2b-4a07-92d2-8387cc97908e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[18]: ['Dest', 'ORIGIN_COUNTRY_NAME', 'count']"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\",\"Dest\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc4d004-cd9b-485b-ae50-163063ba2d30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Dest: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\",\"Dest\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9b984b8-530b-4b3c-bcd3-fc32c04b3929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reserved Characters and Keywords\n",
    "### In Spark, we do this by using backtick (`) characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f448db7f-42f6-4466-87c0-fe70c628096e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|long Col Name|\n+-----------------+-------------------+-----+-------------+\n|    United States|            Romania|   15|United States|\n|    United States|            Croatia|    1|United States|\n+-----------------+-------------------+-----+-------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "dfWithLongColName = df.withColumn(\"long Col Name\",expr(\"DEST_COUNTRY_NAME\"))\n",
    "dfWithLongColName.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d682ead-b8ca-49ce-9120-9fdfe657d242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**We don’t need escape characters here because the first argument to withColumn is just a string\n",
    "for the new column name. In this example, however, we need to use backticks because we’re\n",
    "referencing a column in an expression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d68543-c160-4270-9db0-e5f284a7f9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+-------------+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|long Col Name|      longCol|\n+-----------------+-------------------+-----+-------------+-------------+\n|    United States|            Romania|   15|United States|United States|\n|    United States|            Croatia|    1|United States|United States|\n+-----------------+-------------------+-----+-------------+-------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "dfWithLongColName.selectExpr(\"*\",\"`long Col Name` AS longCol\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99def6de-e401-4417-9e12-ac0d6abe12b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9182fb77-10fc-4d0d-897c-06c9a021fafc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[24]: ['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
     ]
    }
   ],
   "source": [
    "dfWithLongColName.drop(\"long Col Name\",\"longCol\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d37d3d15-dfc7-42fa-8962-17357700fc21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Changing a Column’s Type (cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d914214f-5e29-429a-8c6a-91064f21b259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint, count2: int]"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.withColumn(\"count2\",col(\"count\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f05e34c1-4165-439e-80a9-1d08e64960fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Filtering Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b80a03df-0f2e-4517-ab46-686ff25440c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The most common way to do this with DataFrames is to\n",
    "create either an expression as a String or build an expression by using a set of column\n",
    "manipulations. There are two methods to perform this operation: you can use where or filter\n",
    "and they both will perform the same operation and accept the same argument types when used\n",
    "with DataFrames. We will stick to where because of its familiarity to SQL; however, filter is\n",
    "valid as well.\n",
    "\n",
    "**It is best to build an expression and just use WHERE. This is least confusing way**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c083eb0-f8eb-4fff-aeff-60ae2fa86132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|            Croatia|    1|\n|    United States|          Singapore|    1|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.where(\"count<2\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a9b751c-a28c-4857-9f0d-b30c3e1ed518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th><th>count</th></tr></thead><tbody><tr><td>United States</td><td>Croatia</td><td>1</td></tr><tr><td>United States</td><td>Singapore</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "Croatia",
         1
        ],
        [
         "United States",
         "Singapore",
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from dfTable where count<2 LIMIT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7377945f-95fe-4291-bbb4-68c04eb940e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Instinctually, you might want to put multiple filters into the same expression. Although this is\n",
    "possible, it is not always useful, because Spark automatically performs all filtering operations at\n",
    "the same time regardless of the filter ordering. This means that if you want to specify multiple\n",
    "AND filters, just chain them sequentially and let Spark handle the rest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd991fbb-836d-4168-816f-3b351b58b992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|          Singapore|    1|\n|          Moldova|      United States|    1|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.where(\"count<2\").where(\"ORIGIN_COUNTRY_NAME<>'Croatia'\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "247a6c67-9da1-4ae4-a28e-57cbb3f93afc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th><th>count</th></tr></thead><tbody><tr><td>United States</td><td>Singapore</td><td>1</td></tr><tr><td>Moldova</td><td>United States</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "Singapore",
         1
        ],
        [
         "Moldova",
         "United States",
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from dfTable where count<2 AND ORIGIN_COUNTRY_NAME <> 'Croatia' LIMIT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35ee52c8-ea7f-4984-aa92-4df961cdde87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Getting Unique Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9768ae94-d763-496d-8b55-af83f05d5c12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[33]: 132"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0729111-db3f-413a-8014-7443ba00194d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[34]: 256"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\",\"ORIGIN_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50b2c66c-b7fd-45ce-8882-870cbd734645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Random Samples\n",
    "\n",
    "**fraction**\n",
    "By using fraction between 0 to 1, it returns the approximate number of the fraction of the dataset. For example, 0.1 returns 10% of the rows. However, this does not guarantee it returns the exact 10% of the records.\n",
    "\n",
    "**seed**\n",
    "The random seed is a numerical value that repeats pseudo-random numbers in Python. The value in the random seed saves the state of randomness. For example, If we call the seed function with seed value ‘1’ multiple times, the computer generates the same random numbers. When the value is not mentioned in the random seed, then the computer will use the current system time in seconds or milliseconds as a seed value to generate a different set of random numbers.\n",
    "\n",
    "**withReplacement**\n",
    "some times you may need to get a random sample with repeated values. By using the value true, results in repeated values. It is set to False by Default\n",
    "\n",
    "Example :\n",
    "//Output: 0,5,9,11,14,14,16,17,21,29,33,41,42,52,52,54,58,65,65,71,76,79,85,96\n",
    "On above example, values 14, 52 and 65 are repeated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5197656-650d-46ab-817b-cb6b5240ae58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: 29"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "withReplacement = True\n",
    "fraction = 0.1\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac7ce749-a0a7-4475-a68d-4f90c01ab845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Random Splits\n",
    "Random splits can be helpful when you need to break up your DataFrame into a random “splits”\n",
    "of the original DataFrame. This is often used with machine learning algorithms to create training,\n",
    "validation, and test sets. In this next example, we’ll split our DataFrame into two different\n",
    "DataFrames by setting the weights by which we will split the DataFrame (these are the\n",
    "arguments to the function). Because this method is designed to be randomized, we will also\n",
    "specify a seed (just replace seed with a number of your choosing in the code block). It’s\n",
    "important to note that if you don’t specify a proportion for each DataFrame that adds up to one,\n",
    "they will be normalized so that they do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93d92a44-3a67-4e2f-b37d-98b11415551c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: 69"
     ]
    }
   ],
   "source": [
    "seed = 56\n",
    "dataFrames = df.randomSplit([0.25,0.75],seed)\n",
    "dataFrames[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9498f7d1-5d46-4f08-9c14-5eafc33903ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: 187"
     ]
    }
   ],
   "source": [
    "dataFrames[1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f84b76fc-056e-4a23-ad9f-02431e3df820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Concatenating and Appending Rows (Union)\n",
    "DataFrames are immutable. This means users cannot\n",
    "append to DataFrames because that would be changing it. To append to a DataFrame, you must\n",
    "union the original DataFrame along with the new DataFrame. This just concatenates the two\n",
    "DataFramess. To union two DataFrames, you must be sure that they have the same schema and\n",
    "number of columns; otherwise, the union will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c13f24e2-29d0-485c-a0ea-10a4d24865b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parallelize Method :\n",
    "EXAMPLE :\n",
    "\n",
    "Under the covers, there are quite a few actions that happened when you created your RDD. Let's start with the RDD creation and break down this code snippet:\n",
    "\n",
    "myRDD = sc.parallelize(  [('Mike', 19), ('June', 18), ('Rachel',16), ('Rob', 18), ('Scott', 17)])\n",
    "\n",
    "Focusing first on the statement in the sc.parallelize() method, we first created a Python list (that is, [A, B, ..., E]) composed of a list of arrays (that is, ('Mike', 19), ('June', 19), ..., ('Scott', 17)). The sc.parallelize() method is the SparkContext's parallelize method to create a parallelized collection. **This allows Spark to distribute the data across multiple nodes, instead of depending on a single node to process the data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c165b2d-95e5-423a-97f5-4e8f2cdf3cec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: StructType([StructField('DEST_COUNTRY_NAME', StringType(), True), StructField('ORIGIN_COUNTRY_NAME', StringType(), True), StructField('count', LongType(), True)])"
     ]
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e55af8a-addd-45df-aefd-c91f323d096e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|            India|              India|   10|\n|            Japan|             Russia|   20|\n+-----------------+-------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_new_schema = df.schema\n",
    "my_Rows = [\n",
    "    (\"India\",\"India\",10),\n",
    "    (\"Japan\",\"Russia\",20)\n",
    "]\n",
    "parallelized_rows = spark.sparkContext.parallelize(my_Rows)\n",
    "df_new = spark.createDataFrame(parallelized_rows, df_new_schema)\n",
    "df_new.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c59c0d-bf2f-4b32-9acf-72aaf9a8d1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|            India|              India|   10|\n|            Japan|             Russia|   20|\n+-----------------+-------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.union(df_new)\\\n",
    "    .where(\"count in (10,20)\")\\\n",
    "    .where(\"DEST_COUNTRY_NAME in ('India','Japan')\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2162124f-679b-4110-946f-16c54b0a9946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sorting Rows\n",
    "There are two equivalent operations to do this sort\n",
    "and orderBy that work the exact same way. They accept both column expressions and strings as\n",
    "well as multiple columns. The default is to sort in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1245bfbd-f82c-407c-8603-26baf72163d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|          Moldova|      United States|    1|\n|    United States|            Croatia|    1|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f32fd32-6a8d-43b6-8e30-72903a64e174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|          Moldova|      United States|    1|\n|    United States|            Croatia|    1|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc, desc, expr\n",
    "df.orderBy(expr(\"count desc\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36c10ed5-41e1-49d2-a2a3-bf5f8c673493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|     Burkina Faso|      United States|    1|\n|    Cote d'Ivoire|      United States|    1|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc, desc, expr\n",
    "df.orderBy(expr(\"count desc\"),expr(\"DEST_COUNTRY_NAME desc\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d96b03-24e7-407a-a7cc-71c66269f581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|           Zambia|      United States|    1|\n|        Venezuela|      United States|  290|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc, desc, expr, col\n",
    "df.orderBy(col(\"DEST_COUNTRY_NAME\").desc(),col(\"count\").desc()).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89e041bd-4438-4f9c-87fa-2068f9a19bbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c865d2fb-44e7-4fba-a92f-bc0d97442ac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|            Romania|   15|\n|    United States|            Croatia|    1|\n|    United States|            Ireland|  344|\n|            Egypt|      United States|   15|\n|    United States|              India|   62|\n+-----------------+-------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d84b4a59-d81f-4058-974b-1c751d058341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+--------------------+-------------------+-----+\n|               Malta|      United States|    1|\n|Saint Vincent and...|      United States|    1|\n|       United States|            Croatia|    1|\n|       United States|          Gibraltar|    1|\n|       United States|          Singapore|    1|\n+--------------------+-------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(expr(\"count desc\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c56bcd34-98c6-45da-80f3-69c9367c2289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Repartition and Coalesce\n",
    "Another important optimization opportunity is to partition the data according to some **frequently\n",
    "filtered columns**, which control the physical layout of data across the cluster including the\n",
    "partitioning scheme and the number of partitions.\n",
    "Repartition will incur a full shuffle of the data, regardless of whether one is necessary. This\n",
    "means that you should typically **only repartition when the future number of partitions is greater\n",
    "than your current number of partitions** or when you are looking to partition by a set of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c20ccb1-1cb4-4207-bd0d-6d779b268d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: 1"
     ]
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd5dc2f1-b612-4699-ba18-855adecabb86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[28]: DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
     ]
    }
   ],
   "source": [
    "df.repartition(col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28338617-5bc5-40de-8847-0944738ac909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: 1"
     ]
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b958c6c7-59d4-475b-9bad-b6a6f3e2102c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[31]: DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
     ]
    }
   ],
   "source": [
    "df.repartition(5,col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7842426e-7ae2-4f87-b489-d066eca6f1c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[32]: 1"
     ]
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2945b6a-1c80-477b-9fc0-34118c555b1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Coalesce, on the other hand, will not incur a full shuffle and will try to combine partitions. This\n",
    "operation will shuffle your data into five partitions based on the destination country name, and\n",
    "then coalesce them (without a full shuffle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604d230d-60be-4afc-b7c3-0e5698d0e7f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[33]: DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
     ]
    }
   ],
   "source": [
    "df.repartition(5,col(\"DEST_COUNTRY_NAME\")).coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11262cee-f785-4180-9750-3298923ad556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3356052891311196,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DataFrame Transformations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
