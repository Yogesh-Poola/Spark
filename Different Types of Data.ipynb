{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ca31731-6e19-4565-85cc-d337e78b961f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=6291763126987047#setting/sparkui/0329-062234-llnc4jss/driver-2403042750931910155\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=6291763126987047#setting/sparkui/0329-062234-llnc4jss/driver-2403042750931910155\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d2122fb-c3fd-4769-89a8-2ee7c0d84efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .load(\"dbfs:/FileStore/shared_uploads/creationsbyyogesh@gmail.com/2010_12_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dde85ef-a2c0-42d4-80f5-b03d42bcd60c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "520b8fbe-50c9-40fb-89d0-bf87104c2784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cafdced-7ac2-43d5-a5ec-84fe97bf7fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"df1Table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39de708c-7a47-47b4-9139-8b241a8c05b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initially Data will be in their Native Datatypes. We need to convert them into Spark Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f482d742-afde-4987-afb2-fb7f2ece9360",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|  5|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|  5|\n|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|  5|\n|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|  5|\n|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|  5|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|  5|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df1.select(\"*\",lit(5)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163febc0-e7c2-4836-bf17-fbf7b556598a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n|  5|\n+---+\n|  5|\n|  5|\n|  5|\n|  5|\n|  5|\n+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df1.select(lit(5)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67d77c7c-4dbf-43fd-8acf-966acd33961b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "458a340a-2df4-422a-bdf4-1d81c0a29fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df1.where(col(\"InvoiceNo\")!='536365')\\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed72607-df99-4318-9246-3c90c982db83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n|         Description|       Country|\n+--------------------+--------------+\n|HAND WARMER UNION...|United Kingdom|\n|HAND WARMER RED P...|United Kingdom|\n|ASSORTED COLOUR B...|United Kingdom|\n|POPPY'S PLAYHOUSE...|United Kingdom|\n|POPPY'S PLAYHOUSE...|United Kingdom|\n+--------------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df1.where(col(\"InvoiceNo\")!='536365')\\\n",
    "    .select(\"Description\", \"Country\")\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0313a451-95fc-4b2e-9d5b-f627e417d6d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.where(\"InvoiceNo<>'536365'\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f35399ab-db22-4223-b413-a64377ba859a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Write the following code using pyspark functions\n",
    "\n",
    "SELECT * FROM dfTable WHERE StockCode in (\"DOT\") AND(UnitPrice > 600 OR\n",
    "instr(Description, \"POSTAGE\") >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47a8f3a1-0f4d-4368-9571-919d5211dfbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      null|United Kingdom|\n|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|\n+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "df1.where(col(\"StockCode\").isin(\"DOT\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe08c905-86a7-4aac-9bb0-ceb2602a521f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PySpark AND operator for multiple conditions - &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de99db40-719b-4e55-bf9d-93b108a86369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|\n+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "df1.where(col(\"StockCode\").isin(\"DOT\"))\\\n",
    "    .where((col(\"UnitPrice\")>600) & (instr(col(\"Description\"),\"POSTAGE\")>1)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2fe8592-7cec-4c15-b75f-a7ac68247742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PySpark OR operator for multiple conditions - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b831fac-289d-4fc6-978c-3da161ffed32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      null|United Kingdom|\n|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|\n+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "priceFilter = df1.UnitPrice > 600\n",
    "descriptionFilter = instr(df1.Description,\"POSTAGE\")>=1\n",
    "df1.where(col(\"StockCode\").isin(\"DOT\"))\\\n",
    "    .where(priceFilter | descriptionFilter).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1d00ecb-0200-46ac-af15-bf70cb3c0789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cf7ff7-cd4d-4beb-9103-910a691e3f71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,expr,pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314f7f95-668f-4ac2-bfbc-e55c3ac5c51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fabricatedColumn = pow(col(\"Quantity\") * col(\"UnitPrice\"),2) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb50c22c-e650-4dae-9236-6eebaae03771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n|CustomerID|         TruePrice|\n+----------+------------------+\n|   17850.0|239.08999999999997|\n|   17850.0|          418.7156|\n|   17850.0|             489.0|\n|   17850.0|          418.7156|\n|   17850.0|          418.7156|\n+----------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.select(col(\"CustomerID\"),fabricatedColumn.alias(\"TruePrice\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18df9bc0-be7b-4ee3-b2d6-91f036722b46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|round(2.5, 0)|bround(2.5, 0)|\n+-------------+--------------+\n|          3.0|           2.0|\n|          3.0|           2.0|\n+-------------+--------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "df1.select(round(lit(2.5)), bround(lit(2.5))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aed25840-453a-4cbc-8f18-781429dfdb68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n|summary|        InvoiceNo|         StockCode|         Description|          Quantity|         UnitPrice|        CustomerID|       Country|\n+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n|  count|             3108|              3108|                3098|              3108|              3108|              1968|          3108|\n|   mean| 536516.684944841|27834.304044117645|                null| 8.627413127413128| 4.151946589446603|15661.388719512195|          null|\n| stddev|72.89447869788873|17407.897548583845|                null|26.371821677029203|15.638659854603892|1854.4496996893627|          null|\n|    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|               0.0|           12431.0|     Australia|\n|    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|            607.49|           18229.0|United Kingdom|\n+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "df1.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e940953-be6c-4c28-a663-67071fd489c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "235c557f-4398-46df-b2cf-10778355c9d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, initcap, ltrim, rtrim, trim, lpad, rpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d47f1d-51ab-44f7-b21c-2c324c34cc03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|initcap(Description)|\n+--------------------+\n|White Hanging Hea...|\n| White Metal Lantern|\n|Cream Cupid Heart...|\n|Knitted Union Fla...|\n|Red Woolly Hottie...|\n+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.select(initcap(col(\"Description\"))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "133f8847-3421-4053-8785-673807d815c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "lpad(col, len, pad)\n",
    "\n",
    "rpad(col,len,pad)\tlpad() – Add a specified character as padding on the left side.\n",
    "\n",
    "rpad() – Add a specified character as padding on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a50fa5-9fa2-466d-bdd4-7ca7ba9b096e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----------+----+----------+\n|         LTRIM|         RTRIM|       TRIM|LPAD|      RPAD|\n+--------------+--------------+-----------+----+----------+\n|Hello Madam   |   Hello Madam|Hello Madam|    |   Hello M|\n|Hello Madam   |   Hello Madam|Hello Madam|    |   Hello M|\n+--------------+--------------+-----------+----+----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "string1=\"   Hello Madam   \"\n",
    "df1.select(ltrim(lit(string1)).alias(\"LTRIM\")\\\n",
    "    , rtrim(lit(string1)).alias(\"RTRIM\")\\\n",
    "    , trim(lit(string1)).alias(\"TRIM\")\\\n",
    "    , lpad(lit(string1),3,\" \").alias(\"LPAD\")\\\n",
    "    , rpad(lit(string1),10,\" \").alias(\"RPAD\")\n",
    "           ).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91a75e2e-ff18-4ba8-af32-b3b81950c470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1cdf1d8-ad3f-4898-be9b-3135a391b5b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47efba25-b665-49e5-8123-07894996c3fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n|            Replaced|         Description|\n+--------------------+--------------------+\n|WHI73 H4NGING H34...|WHITE HANGING HEA...|\n| WHI73 M3741 14N73RN| WHITE METAL LANTERN|\n|CR34M CUPID H34R7...|CREAM CUPID HEART...|\n|KNI773D UNION F14...|KNITTED UNION FLA...|\n|R3D WOO11Y HO77I3...|RED WOOLLY HOTTIE...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.select(translate(col(\"Description\"),\"LEAT\",\"1347\").alias(\"Replaced\"),col(\"Description\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed685e1b-2cd3-46f9-9247-22786e02dd47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Date & Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba1aa6b3-a6aa-4024-ae4b-6b0ad18e298a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "635c46d0-9f74-4243-a8b0-1963bdb21f4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n|  5|\n|  6|\n|  7|\n|  8|\n|  9|\n+---+\n\n"
     ]
    }
   ],
   "source": [
    "spark.range(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b2b599-088b-4da7-900d-c20aa3eb5eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfDate = spark.range(10)\\\n",
    "    .withColumn(\"Today Date\",current_date())\\\n",
    "    .withColumn(\"Time Now\",current_timestamp())\n",
    "dfDate.createOrReplaceTempView(\"dfDateTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dca61d6-2a29-42ea-ba6a-8ce12adb2a09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n| id|Today Date|            Time Now|\n+---+----------+--------------------+\n|  0|2025-03-29|2025-03-29 08:30:...|\n|  1|2025-03-29|2025-03-29 08:30:...|\n|  2|2025-03-29|2025-03-29 08:30:...|\n|  3|2025-03-29|2025-03-29 08:30:...|\n|  4|2025-03-29|2025-03-29 08:30:...|\n|  5|2025-03-29|2025-03-29 08:30:...|\n|  6|2025-03-29|2025-03-29 08:30:...|\n|  7|2025-03-29|2025-03-29 08:30:...|\n|  8|2025-03-29|2025-03-29 08:30:...|\n|  9|2025-03-29|2025-03-29 08:30:...|\n+---+----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "dfDate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eacebc1a-8de1-4a59-9cfe-5516b87f4ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = false)\n |-- Today Date: date (nullable = false)\n |-- Time Now: timestamp (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "dfDate.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01de913c-ce2c-4171-9aaf-231cb728a22a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_date_add_**\n",
    "\n",
    "**_date_sub_**\n",
    "\n",
    "**_datediff_**\n",
    "\n",
    "**_months_between_**\n",
    "\n",
    "**_to_date_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7af19c6d-8bab-446b-9429-fafe1847d9a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_sub, date_add, datediff, months_between, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5966265b-976e-42ee-9a56-6a8edb7a089b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n| id|Today Date|            Time Now|\n+---+----------+--------------------+\n|  0|2025-03-29|2025-03-29 08:39:...|\n|  1|2025-03-29|2025-03-29 08:39:...|\n|  2|2025-03-29|2025-03-29 08:39:...|\n|  3|2025-03-29|2025-03-29 08:39:...|\n|  4|2025-03-29|2025-03-29 08:39:...|\n|  5|2025-03-29|2025-03-29 08:39:...|\n|  6|2025-03-29|2025-03-29 08:39:...|\n|  7|2025-03-29|2025-03-29 08:39:...|\n|  8|2025-03-29|2025-03-29 08:39:...|\n|  9|2025-03-29|2025-03-29 08:39:...|\n+---+----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "dfDate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d88bf39-49ed-4cc1-9098-4b5b680a713d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+------------+------------+\n| id|Today Date|            Time Now|5 Days Prior|5 Days Later|\n+---+----------+--------------------+------------+------------+\n|  0|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  1|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  2|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  3|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  4|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  5|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  6|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  7|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  8|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n|  9|2025-03-29|2025-03-29 08:41:...|  2025-03-24|  2025-04-03|\n+---+----------+--------------------+------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "dfDate.select(\"*\",date_sub(col(\"Today Date\"),5).alias(\"5 Days Prior\"),date_add(col(\"Today Date\"),5).alias(\"5 Days Later\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5495a759-e812-48cc-876e-0e5c8c0fc175",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Difference between two dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40d54f67-6ffe-481e-b415-417055585de9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n|Today Date|Difference in Days|\n+----------+------------------+\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n|2025-03-29|               -61|\n+----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "randomDate = to_date(lit('2025-01-27'))\n",
    "dfDate.select(col(\"Today Date\"),datediff(randomDate,col(\"Today Date\")).alias(\"Difference in Days\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ea1a2e7-bac2-4c04-a68a-1ec605b952c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Months Between two dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87bdf24c-51a0-4f93-bfd4-737013ea35be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n|months_between(to_date(2024-09-12), to_date(2025-02-28), true)|\n+--------------------------------------------------------------+\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n|                                                   -5.51612903|\n+--------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "startDate = to_date(lit('2024-09-12'))\n",
    "endDate = to_date(lit('2025-02-28'))\n",
    "dfDate.select(months_between(startDate, endDate)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de913888-d48d-44bb-a1ce-4d4626352d3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**let’s take a look at the date format that has switched from year-month-day to year-day-month. Spark will fail to parse this date and silently return null instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f002588-bbb9-4372-95ed-5e0a7a2d172d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n|to_date(2016-20-12)|to_date(2017-12-11)|\n+-------------------+-------------------+\n|               null|         2017-12-11|\n+-------------------+-------------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "dfDate.select(to_date(lit(\"2016-20-12\")),to_date(lit(\"2017-12-11\"))).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2018ddff-a765-41a6-97d6-ce0520d8b279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_We find this to be an especially tricky situation for bugs because some dates might match the\n",
    "correct format, whereas others do not. In the previous example, notice how the second date\n",
    "appears as Decembers 11th instead of the correct day, November 12th. Spark doesn’t throw an\n",
    "error because it cannot know whether the days are mixed up or that specific row is incorrect.\n",
    "Let’s fix this pipeline, step by step, and come up with a robust way to avoid these issues entirely.\n",
    "The first step is to remember that we need to specify our date format according to the Java\n",
    "SimpleDateFormat standard.\n",
    "We will use two functions to fix this: to_date and to_timestamp. The former optionally\n",
    "expects a format, whereas the latter requires one:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a4ca67a-d15c-4a30-a9ca-516f0d05ddf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n|     date1|     date2|\n+----------+----------+\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n|2016-12-20|2017-11-12|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "dateFormat ='yyyy-dd-MM'\n",
    "cleanedDfDate = dfDate.select(to_date(lit(\"2016-20-12\"),dateFormat).alias(\"date1\")\\\n",
    "    , to_date(lit(\"2017-12-11\"),dateFormat).alias(\"date2\"))\n",
    "cleanedDfDate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47f8e7da-804f-4116-8833-116edc4af2bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n|to_timestamp(date1, yyyy-dd-MM)|\n+-------------------------------+\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n|            2016-12-20 00:00:00|\n+-------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "cleanedDfDate.select(to_timestamp(col(\"date1\"),dateFormat)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "194477a9-fdf9-45b9-85ee-cfe75bf49f9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Different Types of Data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}